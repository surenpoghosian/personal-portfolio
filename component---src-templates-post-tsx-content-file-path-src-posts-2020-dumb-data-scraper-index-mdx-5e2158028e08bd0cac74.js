(self.webpackChunksurenpoghosian_github_io=self.webpackChunksurenpoghosian_github_io||[]).push([[191],{9016:function(e,t,a){var n=a(5972).k5;e.exports.w=function(e){return n({tag:"svg",attr:{viewBox:"0 0 24 24"},child:[{tag:"path",attr:{d:"M11.953,2C6.465,2,2,6.486,2,12s4.486,10,10,10s10-4.486,10-10S17.493,2,11.953,2z M12,20c-4.411,0-8-3.589-8-8 s3.567-8,7.953-8C16.391,4,20,7.589,20,12S16.411,20,12,20z"}},{tag:"path",attr:{d:"M11 7H13V14H11zM11 15H13V17H11z"}}]})(e)}},3036:function(e,t,a){var n=a(5972).k5;e.exports.C=function(e){return n({tag:"svg",attr:{viewBox:"0 0 16 16",fill:"currentColor"},child:[{tag:"path",attr:{fillRule:"evenodd",d:"M8 16A8 8 0 108 0a8 8 0 000 16zm.93-9.412l-2.29.287-.082.38.45.083c.294.07.352.176.288.469l-.738 3.468c-.194.897.105 1.319.808 1.319.545 0 1.178-.252 1.465-.598l.088-.416c-.2.176-.492.246-.686.246-.275 0-.375-.193-.304-.533L8.93 6.588zM8 5.5a1 1 0 100-2 1 1 0 000 2z",clipRule:"evenodd"}}]})(e)}},5018:function(e,t,a){var n=a(5972).k5;e.exports.w=function(e){return n({tag:"svg",attr:{viewBox:"0 0 24 24",fill:"none",stroke:"currentColor",strokeWidth:"2",strokeLinecap:"round",strokeLinejoin:"round"},child:[{tag:"rect",attr:{x:"3",y:"4",width:"18",height:"18",rx:"2",ry:"2"}},{tag:"line",attr:{x1:"16",y1:"2",x2:"16",y2:"6"}},{tag:"line",attr:{x1:"8",y1:"2",x2:"8",y2:"6"}},{tag:"line",attr:{x1:"3",y1:"10",x2:"21",y2:"10"}}]})(e)}},2572:function(e,t,a){var n=a(5972).k5;e.exports.O=function(e){return n({tag:"svg",attr:{viewBox:"0 0 24 24",fill:"none",stroke:"currentColor",strokeWidth:"2",strokeLinecap:"round",strokeLinejoin:"round"},child:[{tag:"circle",attr:{cx:"12",cy:"12",r:"10"}},{tag:"polyline",attr:{points:"12 6 12 12 16 14"}}]})(e)}},7864:function(e,t,a){"use strict";a.r(t),a.d(t,{default:function(){return c}});var n=a(8453),r=a(6540);function l(e){const t=Object.assign({p:"p",h2:"h2",a:"a",span:"span",ul:"ul",li:"li"},(0,n.RP)(),e.components);return r.createElement(r.Fragment,null,r.createElement(t.p,null,"In this project, I built a powerful data scraper using Python, Selenium, and Qt. This bot was designed to collect data from Instagram, automatically navigating through different profiles and hashtags. The goal was to gather useful information that could help uncover trends and patterns on the platform."),"\n",r.createElement(t.h2,{id:"how-the-scraper-works",style:{position:"relative"}},"How the Scraper Works",r.createElement(t.a,{href:"#how-the-scraper-works","aria-label":"how the scraper works permalink",className:"gatsby-remark-autolink-header-anchor after"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}}))),"\n",r.createElement(t.p,null,"The bot uses Selenium, a tool that allows you to control a web browser through code. With Selenium, I was able to log into Instagram, search for specific hashtags or profiles, and then scrape the data from these pages. I used Python to write the code that controls Selenium, while Qt helped create a simple user interface for the scraper."),"\n",r.createElement(t.p,null,"Once the bot collects the data, it can be used to analyze things like the most popular posts, user activity, or hashtag performance. The scraper pulls information such as:"),"\n",r.createElement(t.ul,null,"\n",r.createElement(t.li,null,"Post captions"),"\n",r.createElement(t.li,null,"Usernames"),"\n",r.createElement(t.li,null,"Number of likes and comments"),"\n",r.createElement(t.li,null,"Hashtags used"),"\n"),"\n",r.createElement(t.h2,{id:"capturing-followers-and-following-trees",style:{position:"relative"}},"Capturing Followers and Following Trees",r.createElement(t.a,{href:"#capturing-followers-and-following-trees","aria-label":"capturing followers and following trees permalink",className:"gatsby-remark-autolink-header-anchor after"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}}))),"\n",r.createElement(t.p,null,"Alongside scraping post data, the bot was designed to capture the followers and following tree of the requested user. This feature allows the bot to gather detailed information about not just who the user follows, but also who follows them. By building a network map of these connections, the bot can analyze relationships between different accounts on Instagram."),"\n",r.createElement(t.p,null,"For example, if the bot identifies that a particular user follows another user, it can explore the latter’s network further, pulling in data about their followers and who they follow. This enables a more comprehensive understanding of social dynamics on the platform. By saving this information in a structured format, I could easily query the data later to discover connections between users, find common followers, or identify influential accounts within specific communities."),"\n",r.createElement(t.p,null,"This capability opens up exciting possibilities for analyzing social media behavior, as it helps track trends in user engagement and discover potential collaborations or marketing opportunities. The follower and following data enriches the overall dataset, allowing for deeper insights into how users interact with each other on Instagram."),"\n",r.createElement(t.h2,{id:"challenges-in-scraping-instagram",style:{position:"relative"}},"Challenges in Scraping Instagram",r.createElement(t.a,{href:"#challenges-in-scraping-instagram","aria-label":"challenges in scraping instagram permalink",className:"gatsby-remark-autolink-header-anchor after"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}}))),"\n",r.createElement(t.p,null,"One of the toughest parts of this project was dealing with Instagram’s security features, which sometimes block bots from accessing their site. I had to make the bot act like a regular user by adding small delays between actions, so it wouldn’t get detected. It took some trial and error to find the right balance, but eventually, the bot was able to scrape data without any issues."),"\n",r.createElement(t.p,null,"Another challenge was handling dynamic content, like infinite scrolling. Instagram loads more posts as you scroll down the page, so the bot had to keep scrolling to get all the data. I had to write code that would automatically scroll down and load more content before collecting the data."),"\n",r.createElement(t.h2,{id:"using-the-data-for-analysis",style:{position:"relative"}},"Using the Data for Analysis",r.createElement(t.a,{href:"#using-the-data-for-analysis","aria-label":"using the data for analysis permalink",className:"gatsby-remark-autolink-header-anchor after"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}}))),"\n",r.createElement(t.p,null,"Once the data was scraped, I saved it into a CSV file. This made it easy to work with in programs like Excel or Pandas (a Python library for data analysis). With the data, I could see which posts were the most popular, which hashtags were trending, and even how often certain users were active on the platform."),"\n",r.createElement(t.p,null,"This kind of data is useful for social media marketing, helping users and businesses understand what works best on Instagram."),"\n",r.createElement(t.p,null,"Building this Instagram scraper was a fun and rewarding experience. By combining Python, Selenium, and Qt, I was able to create a tool that collects data automatically and efficiently. Although there were challenges along the way, like bypassing security measures and dealing with dynamic content, it taught me a lot about web scraping and handling large amounts of data."),"\n",r.createElement(t.p,null,"If you’re looking to dive into web scraping or just want to explore data from social media platforms, I recommend trying out Python and Selenium. They’re powerful tools that can open up many possibilities for data analysis!"))}var o=function(e){void 0===e&&(e={});const{wrapper:t}=Object.assign({},(0,n.RP)(),e.components);return t?r.createElement(t,e,r.createElement(l,e)):l(e)},i=a(9713);const s=e=>{const{data:t,children:a}=e;return r.createElement(i.A,{post:t},a)};function c(e){return r.createElement(s,e,r.createElement(o,e))}},9713:function(e,t,a){"use strict";a.d(t,{A:function(){return m}});var n=a(6540),r=a(90),l=a(5018),o=a(2572),i=a(7257),s=a(6911),c=a(6835),u=a(2807);var h=e=>{var t,a,r,h,d,m,p;const{post:f,children:g}=e,v=null!=f&&null!==(t=f.mdx)&&void 0!==t&&null!==(a=t.frontmatter)&&void 0!==a&&a.date?n.createElement(s.A,{className:"mr-6 mb-6 text-gray-500 text-sm"},n.createElement(l.w,{className:"mr-1"}),null==f||null===(r=f.mdx)||void 0===r?void 0:r.frontmatter.date):null,w=null!=f&&null!==(h=f.mdx)&&void 0!==h&&h.timeToRead?n.createElement(s.A,null,n.createElement(o.O,{className:"mr-1"}),(0,c.d)(null==f||null===(d=f.mdx)||void 0===d?void 0:d.timeToRead)," min to read"):null;return n.createElement("div",{className:"flex flex-col items-center"},n.createElement("article",{className:"w-full prose prose-sm sm:prose overflow-hidden prose-red",style:{maxWidth:"860px"}},n.createElement(i.A,null,(null===(m=f.mdx)||void 0===m||null===(p=m.frontmatter)||void 0===p?void 0:p.title)||""),n.createElement(s.A,null,v,w),n.createElement(u.A,null,g)))},d=a(5366);var m=e=>{var t,a,l,o,i,s,c,u,m,p,f;const{post:g,children:v}=e;return n.createElement(r.A,null,n.createElement(d.Ay,{title:(null===(t=g.mdx)||void 0===t||null===(a=t.frontmatter)||void 0===a?void 0:a.title)||"",titleMode:d.d5,description:(null===(l=g.mdx)||void 0===l||null===(o=l.frontmatter)||void 0===o?void 0:o.summary)||"",image:(null===(i=g.mdx)||void 0===i||null===(s=i.frontmatter)||void 0===s||null===(c=s.cover)||void 0===c||null===(u=c.childImageSharp)||void 0===u||null===(m=u.gatsbyImageData)||void 0===m||null===(p=m.images)||void 0===p||null===(f=p.fallback)||void 0===f?void 0:f.src)||"",type:d.JX}),n.createElement(h,{post:g},v))}},9797:function(e,t,a){"use strict";a.d(t,{$p:function(){return s}});var n=a(6540),r=a(3036),l=a(9016),o=a(6911);const i="info",s="error",c={[i]:n.createElement(r.C,{size:18}),[s]:n.createElement(l.w,{size:18})},u={[i]:"text-blue-600 bg-blue-100",[s]:"text-red-600 bg-red-100"};t.Ay=e=>{const{children:t,type:a}=e;return t?n.createElement("div",{className:`py-3 px-4 rounded-md ${u[a]}`},n.createElement(o.A,null,n.createElement("div",{className:"mr-3"},c[a]),n.createElement("div",{className:"text-sm"},t))):null}},2807:function(e,t,a){"use strict";var n=a(5540),r=a(6540),l=a(9797);let o=function(e){function t(t){var a;return(a=e.call(this,t)||this).state={hasError:!1},a}(0,n.A)(t,e),t.getDerivedStateFromError=function(){return{hasError:!0}};var a=t.prototype;return a.componentDidCatch=function(e,t){console.error(e,t),this.setState({hasError:!0})},a.render=function(){const{children:e}=this.props,{hasError:t}=this.state;return t?r.createElement(l.Ay,{type:l.$p},"Component has crashed"):e},t}(r.Component);t.A=o},7257:function(e,t,a){"use strict";var n=a(6540),r=a(4523);t.A=e=>{const{children:t,className:a=""}=e,l=`mb-6 uppercase font-extrabold ${a}`;return n.createElement(r.A,{level:r.p.h1,className:l},t)}},6835:function(e,t,a){"use strict";a.d(t,{d:function(){return n}});const n=e=>{if("number"!=typeof e)return null;return Math.ceil(1*e)||1}},8453:function(e,t,a){"use strict";a.d(t,{RP:function(){return l}});var n=a(6540);const r=n.createContext({});function l(e){const t=n.useContext(r);return n.useMemo((()=>"function"==typeof e?e(t):{...t,...e}),[t,e])}}}]);
//# sourceMappingURL=component---src-templates-post-tsx-content-file-path-src-posts-2020-dumb-data-scraper-index-mdx-5e2158028e08bd0cac74.js.map